{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lWMeUWJOcbz-",
        "fE5Z0vGsTBlp",
        "EoTY3gWAtT4x"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####License"
      ],
      "metadata": {
        "id": "lwGy6EsH-DIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Copyright 2024 Google LLC\n",
        "\n",
        "#Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#you may not use this file except in compliance with the License.\n",
        "#You may obtain a copy of the License at\n",
        "\n",
        "#    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "#Unless required by applicable law or agreed to in writing, software\n",
        "#distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#See the License for the specific language governing permissions and\n",
        "#limitations under the License."
      ],
      "metadata": {
        "id": "2KvXqY_i-K8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Google Colab GA4 Easy Datamart Preparation\n",
        "![Placeholder Image](https://drive.google.com/uc?export=view&id=1eNinLEkFUGqT8M98C-3mhGYzngX141CG)\n",
        "\n",
        "This Google Colab notebook facilitates the creation of a user-level datamart using Google Analytics 4 (GA4) data. The process involves building a SQL query to be executed in BigQuery, resulting in a customized datamart for analysis. The script utilizes various parameters provided by the user to tailor the datamart creation process. Recommended if you have sizeable logged in user data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Code Execution:**\n",
        "\n",
        "The script begins by authenticating the user and initializing the BigQuery client. It then proceeds to format the provided time window and constructs a user mapping table query to associate user pseudo-IDs with user IDs. This mapping is crucial for attributing past behavior to a unified user ID.\n",
        "\n",
        "The user ID input is processed based on the provided alias, allowing flexibility in handling user identification. The resulting SQL query is saved to a file for reference.\n",
        "\n",
        "Custom events for predictive audiences are then processed, allowing users to specify events for inclusion in the datamart. The SQL queries are dynamically adjusted based on user input.\n",
        "\n",
        "Finally, the user mapping and datamart queries are executed in BigQuery, creating the desired user-level datamart for analysis.\n",
        "The resulting datamart can be used for user level measurement and feature engineering in ML applications. Includes built in RFM+ metrics (user engagement, purchase behavior).\n",
        "\n",
        "The output data dictionary: [link](https://docs.google.com/spreadsheets/d/12FJzkwUl3gEjMNgvtLzqLKOsCxKy4Mog-8AYbuEXPdc/edit?pli=1&resourcekey=0-b1BaOperI3qQlrlQh29wIg#gid=601097648)\n",
        "\n",
        "Detailed implementation doc: [link](https://docs.google.com/document/d/1WTVFEOfacX3flo8eExh3J6gyKVEOpItN_WKC5RMehYI/edit?resourcekey=0-SavOE28uPRruGefuKDrthQ&tab=t.0#heading=h.6mwpcxb2gxe9)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Note: Ensure proper authentication and authorization for GCP and BigQuery to execute the script successfully."
      ],
      "metadata": {
        "id": "2aOzphABtGV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "U3rrJCLYGnAI"
      },
      "outputs": [],
      "source": [
        "#@title Inputs\n",
        "GCP_Job_project_name = \"turkey-analytical-projects\" #@param {type:\"string\"}\n",
        "GCP_Job_region = \"EU\" #@param {type:\"string\"}\n",
        "Big_query_project_name = \"arcelik-bi-project\" #@param {type:\"string\"}\n",
        "Data_set_name = \"goog123\" #@param {type:\"string\"}\n",
        "GA4_table_name = \"analytics_294368252\" #@param {type:\"string\"}\n",
        "User_id_alias = \"user_id\" #@param {type:\"string\"}\n",
        "App_stream_to_ga4 = False #@param {type:\"boolean\"}\n",
        "Have_Ga4_custom_audiences = False #@param {type:\"boolean\"}\n",
        "Ga4_custom_audience_event_names = \"\" #@param {type:\"string\"}\n",
        "Datamart_start_date= \"2024-11-01\" #@param {type:\"date\"}\n",
        "Datamart_end_date= \"2024-11-03\" #@param {type:\"date\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Fill the fields with desired parameters to build the userdatamart:*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **GCP_Job_project_name:** Google Cloud Platform (GCP) project name for job execution.\n",
        "\n",
        "\n",
        "* **GCP_Job_region:** GCP region for job execution. (make sure that the dataset and events tables are at the same region)\n",
        "\n",
        "\n",
        "* **Big_query_project_name:** Project name in BigQuery where the datamart will be created\n",
        "\n",
        "\n",
        "* **Data_set_name:** Name of the dataset within the specified BigQuery project. Tables will be created under this dataset.\n",
        "\n",
        "\n",
        "* **GA4_table_name:** Name of the GA4 table containing the events data. Exp: analytics_12345\n",
        "\n",
        "\n",
        "* **User_id_alias:** Alias for user identification, supporting nested properties and direct user ID references.If the user_id is recorder in user_id column in GA4 data just keep it as \"user_id\". If the user_id is recorded under user_properties parameters of GA4, make the value: \"user_properties, user_id, string_value\" comma delimited.\n",
        "\n",
        "\n",
        "* **App_stream_to_ga4:** Boolean indicating whether app streaming data should be included.\n",
        "\n",
        "\n",
        "* **Have_Ga4_custom_audiences:** Boolean indicating whether custom GA4 audiences are to be included.Check the box if you have pre-built custom/predictive audiences and want to export it to user datamart.\n",
        "\n",
        "\n",
        "* **Ga4_custom_audience_event_names:** Names of custom events triggering GA4 custom audiences. If you don't have custom audiences, make sure you unchecked the previous box. Can accept up to 3 event triggers delimited by comma. Exp: likely_sevenday_purchasers, first_time_sevenday_purchasers, likely_sevenday_churning\n",
        "\n",
        "\n",
        "* **Datamart_start_date:** Start date for the datamart time window.\n",
        "\n",
        "\n",
        "* **Datamart_end_date:** End date for the datamart time window."
      ],
      "metadata": {
        "id": "Fog2qcDn-VqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate"
      ],
      "metadata": {
        "id": "lWMeUWJOcbz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import data_table\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_gbq\n",
        "import datetime\n",
        "project = GCP_Job_project_name # Project ID to run the job\n",
        "location = GCP_Job_region # Location inserted based on the query results selected to explore\n",
        "client = bigquery.Client(project=project, location=location)\n",
        "data_table.enable_dataframe_formatter()\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "dLISUsfJcfkn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build GA4 user datamart"
      ],
      "metadata": {
        "id": "FBCd0Nry-rpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build user_id mapping table"
      ],
      "metadata": {
        "id": "fE5Z0vGsTBlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create the dataset\n",
        "def create_dataset(project_id, dataset_id, location):\n",
        "\n",
        "  # Create the dataset reference\n",
        "  dataset_ref = client.dataset(dataset_id, project=project_id)\n",
        "\n",
        "  # Specify the dataset properties (optional)\n",
        "  dataset = bigquery.Dataset(dataset_ref)\n",
        "  dataset.location = location  # Change the location as needed\n",
        "\n",
        "  # Create the dataset\n",
        "  client.create_dataset(dataset, exists_ok=True)\n",
        "  print(f\"Dataset {dataset_id} created.\")\n",
        "\n",
        "\n",
        "create_dataset(project_id=Big_query_project_name, dataset_id=Data_set_name, location=location)\n",
        "\n",
        "\n",
        "# time formatting for query\n",
        "last_date_sql = \"\"\"CAST('last_date' AS DATE)\"\"\".replace(\"last_date\", Datamart_end_date)\n",
        "\n",
        "def reformat_date(date):\n",
        "  date = date.replace(\"-\", \"\")\n",
        "  return date\n",
        "\n",
        "table_suffix_start_date = reformat_date(Datamart_start_date)\n",
        "table_suffix_end_date = reformat_date(Datamart_end_date)\n",
        "time_frame = f\"(_TABLE_SUFFIX BETWEEN '{table_suffix_start_date}' AND '{table_suffix_end_date}')\"\n",
        "\n",
        "# create the user_id mapping table query\n",
        "\n",
        "user_id_mapping_query= f\"\"\"\n",
        "\n",
        "create or replace table `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as\n",
        "(\n",
        "with u0 as (\n",
        "select\n",
        "user_pseudo_id,\n",
        "user_id_place_holder as fixed_user_id,\n",
        "event_date\n",
        "from `{Big_query_project_name}.{GA4_table_name}.events_*`\n",
        "-- where {time_frame}\n",
        ")\n",
        "\n",
        "---- user id user_pseudo_id mapping using last date events\n",
        "\n",
        "select\n",
        "* except(rn)\n",
        "from\n",
        "(\n",
        "select\n",
        "user_pseudo_id,\n",
        "fixed_user_id as user_id,\n",
        "row_number() over (partition by user_pseudo_id order by event_date desc) as rn\n",
        "from u0\n",
        "where fixed_user_id is not null\n",
        ")\n",
        "where rn = 1\n",
        ");\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def user_id_input_fix(User_id_alias, user_id_mapping_query):\n",
        "  if \"user_properties\" in User_id_alias:\n",
        "    print(\"user_id is nested in user_properties column in ga4\")\n",
        "    user_properties,field_name,value_type = User_id_alias.split(\",\")\n",
        "    field_name = field_name.strip()\n",
        "    value_type = value_type.strip()\n",
        "\n",
        "    user_id_snippet= \"\"\"(select value.value_type from unnest(user_properties) where key='field_name')\"\"\".replace(\"field_name\", field_name)\n",
        "    user_id_snippet= user_id_snippet.replace(\"value_type\", value_type)\n",
        "\n",
        "    user_id_mapping_query = user_id_mapping_query.replace(\"user_id_place_holder\", user_id_snippet)\n",
        "    print(user_id_mapping_query)\n",
        "    return user_id_mapping_query\n",
        "\n",
        "  elif \"user_id\" in User_id_alias:\n",
        "    print(\"user_id in user_id column in ga4\")\n",
        "    user_id_mapping_query = user_id_mapping_query.replace(\"user_id_place_holder\", \"user_id\")\n",
        "    print(user_id_mapping_query)\n",
        "    return user_id_mapping_query\n",
        "\n",
        "  else:\n",
        "    print(\"Re check user_id alisa input! Make sure that it is seperated with comas\")\n",
        "\n",
        "\n",
        "user_id_mapping_query= user_id_input_fix(User_id_alias, user_id_mapping_query)\n",
        "\n",
        "# Specify the file name\n",
        "file_name = \"user_id_mapping_query.sql\"  # You can use .sql extension to indicate that it is an SQL file\n",
        "\n",
        "# Write the SQL query to the file\n",
        "with open(file_name, \"w\") as file:\n",
        "    file.write(user_id_mapping_query)\n",
        "\n",
        "print(f\"The SQL query has been saved to {file_name}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPWwXG-CHEaE",
        "outputId": "8086e0f1-5af3-4bb3-c221-2ea8e561dfac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset goog123 created.\n",
            "user_id in user_id column in ga4\n",
            "\n",
            "\n",
            "create or replace table `arcelik-bi-project.goog123.user_mapping_table` as\n",
            "(\n",
            "with u0 as (\n",
            "select\n",
            "user_pseudo_id,\n",
            "user_id as fixed_user_id,\n",
            "event_date\n",
            "from `arcelik-bi-project.analytics_294368252.events_*`\n",
            "-- where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103')\n",
            ")\n",
            "\n",
            "---- user id user_pseudo_id mapping using last date events\n",
            "\n",
            "select\n",
            "* except(rn)\n",
            "from\n",
            "(\n",
            "select\n",
            "user_pseudo_id,\n",
            "fixed_user_id as user_id,\n",
            "row_number() over (partition by user_pseudo_id order by event_date desc) as rn\n",
            "from u0\n",
            "where fixed_user_id is not null\n",
            ")\n",
            "where rn = 1\n",
            ");\n",
            "\n",
            "\n",
            "\n",
            "The SQL query has been saved to user_id_mapping_query.sql.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build user datamart query"
      ],
      "metadata": {
        "id": "iXa-PC1sNqGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom audience triggers query"
      ],
      "metadata": {
        "id": "vdURHKO8VZLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adjust the section for ga4 predictive audiences query\n",
        "pred_query =\"\"\"max(case when event_name = 'likely_sevenday_purchasers' then 1 else 0 end) as likely_sevenday_purchasers,\n",
        "max(case when event_name = 'first_time_sevenday_purchasers' then 1 else 0 end) as first_time_sevenday_purchasers,\n",
        "max(case when event_name = 'likely_sevenday_churning' then 1 else 0 end) as likely_sevenday_churning\n",
        "\"\"\"\n",
        "\n",
        "null_adjust_pred_aud= \"\"\"IFNULL(likely_sevenday_purchasers, 0) as likely_sevenday_purchasers,\n",
        "IFNULL(first_time_sevenday_purchasers, 0) as first_time_sevenday_purchasers,\n",
        "IFNULL(likely_sevenday_churning, 0) as likely_sevenday_churning,\"\"\"\n",
        "\n",
        "\n",
        "#get the input and clean it\n",
        "pred_events=[event.strip() for event in Ga4_custom_audience_event_names.split(\",\")]\n",
        "\n",
        "if len(pred_events) == 1:\n",
        "  pred_query=pred_query.replace(pred_query,f\"max(case when event_name = '{pred_events[0]}' then 1 else 0 end) as {pred_events[0]}\")\n",
        "  null_adjust_pred_aud=null_adjust_pred_aud.replace(null_adjust_pred_aud,f\"\"\"IFNULL({pred_events[0]}, 0) as {pred_events[0]},\"\"\")\n",
        "\n",
        "elif len(pred_events) == 2:\n",
        "  pred_query=pred_query.replace(pred_query,f\"\"\"max(case when event_name = '{pred_events[0]}' then 1 else 0 end) as {pred_events[0]},\n",
        "max(case when event_name = '{pred_events[1]}' then 1 else 0 end) as {pred_events[1]}\"\"\")\n",
        "  null_adjust_pred_aud=null_adjust_pred_aud.replace(null_adjust_pred_aud,f\"\"\"IFNULL({pred_events[0]}, 0) as {pred_events[0]},\n",
        "IFNULL({pred_events[1]}, 0) as {pred_events[1]},\"\"\")\n",
        "\n",
        "elif len(pred_events) == 3:\n",
        "  pred_query=pred_query.replace(pred_query,f\"\"\"max(case when event_name = '{pred_events[0]}' then 1 else 0 end) as {pred_events[0]},\n",
        "max(case when event_name = '{pred_events[1]}' then 1 else 0 end) as {pred_events[1]},\n",
        "max(case when event_name = '{pred_events[2]}' then 1 else 0 end) as {pred_events[2]}\"\"\")\n",
        "  null_adjust_pred_aud=null_adjust_pred_aud.replace(null_adjust_pred_aud,f\"\"\"IFNULL({pred_events[0]}, 0) as {pred_events[0]},\n",
        "IFNULL({pred_events[1]}, 0) as {pred_events[1]},\n",
        "IFNULL({pred_events[2]}, 0) as {pred_events[2]},\"\"\")\n",
        "\n",
        "elif len(pred_events) > 3:\n",
        "  print(\"too much events\")\n",
        "  Have_Ga4_custom_audiences=False\n",
        "\n",
        "print(pred_events)\n",
        "print(len(pred_events))\n",
        "print(pred_query)\n",
        "print(null_adjust_pred_aud)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7WSWiT8OH_Y",
        "outputId": "2abc1e46-bf0a-45a8-9ef9-f7c3e96a3021"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['']\n",
            "1\n",
            "max(case when event_name = '' then 1 else 0 end) as \n",
            "IFNULL(, 0) as ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_datamart_query= f\"\"\"\n",
        "create or replace table `{Big_query_project_name}.{Data_set_name}.user_id_data_ga4_{table_suffix_start_date}_{table_suffix_end_date}` as\n",
        "--- geo, device info, user_ltv —\n",
        "-- for each user assign the latest observed device\n",
        "with t1 as(\n",
        "select\n",
        "* except(RN)\n",
        "from\n",
        " (SELECT\n",
        " u1.user_id,\n",
        "\n",
        "\n",
        " geo.continent,\n",
        " geo.sub_continent,\n",
        " geo.region,\n",
        " geo.country,\n",
        " geo.city,\n",
        "\n",
        "\n",
        " device.category,\n",
        " device.mobile_brand_name,\n",
        " device.operating_system,\n",
        "\n",
        "\n",
        " user_first_touch_timestamp,\n",
        " user_ltv.revenue as user_ltv,\n",
        "\n",
        "\n",
        " row_number() over (partition by u1.user_id order by event_date desc) as RN\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and u1.user_id is not null\n",
        "   )\n",
        "where RN = 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- last events\n",
        "t2 as (\n",
        " select * except(RN)\n",
        " from\n",
        "   (SELECT\n",
        "   u1.user_id,\n",
        "   event_date as last_event_date,\n",
        "   event_name as last_event_name,\n",
        "   IFNULL(traffic_source.name, 'NOTSET') as last_traffic_source_name,\n",
        "   IFNULL(traffic_source.medium,'NOTSET') as last_traffic_source_medium,\n",
        "   IFNULL(traffic_source.`source`, 'NOTSET') as last_traffic_source_source,\n",
        "   row_number() over (partition by u1.user_id order by event_date desc) as RN\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and u1.user_id is not null    )\n",
        " where RN = 1\n",
        ")\n",
        ",\n",
        "-- join tables\n",
        "p1 as (\n",
        "select\n",
        "t1.*,\n",
        "t2.*  except(user_id)\n",
        "from t1\n",
        "left join t2 on t1.user_id = t2.user_id\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- total pageviews and the distinct days page viewed (visit frequency)\n",
        "\n",
        "\n",
        "pw as (\n",
        "select\n",
        "u1.user_id,\n",
        "\n",
        "\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then 1 else 0 end) ) as number_of_page_views_7D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then 1 else 0 end) ) as number_of_page_views_14D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then 1 else 0 end) ) as number_of_page_views_30D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then 1 else 0 end) ) as number_of_page_views_60D,\n",
        "\n",
        "\n",
        "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then event_date else null end) ) as visit_freq_7D,\n",
        "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then event_date else null end) ) as visit_freq_14D,\n",
        "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then event_date else null end) ) as visit_freq_30D,\n",
        "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then event_date else null end) ) as visit_freq_60D\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'page_view' and u1.user_id is not null\n",
        "   group by 1\n",
        "\n",
        "),\n",
        "\n",
        "\n",
        "p2 as(\n",
        "select\n",
        "p1.*,\n",
        "pw.* except(user_id)\n",
        "from p1\n",
        "left join pw on p1.user_id=pw.user_id\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- visit durations\n",
        "vd as (\n",
        "select\n",
        "u1.user_id,\n",
        "\n",
        "\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then ep.value.int_value else 0 end) )/1000 as visit_duration_7Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then ep.value.int_value else 0 end) )/1000 as visit_duration_14Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then ep.value.int_value else 0 end) )/1000 as visit_duration_30Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then ep.value.int_value else 0 end) )/1000 as visit_duration_60Ds\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x, unnest(event_params) as ep\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'page_view' and ep.key ='engagement_time_msec' and u1.user_id is not null\n",
        "   group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- screen view and screen view durations (use if app is also linked with GA4)\n",
        "sw as (\n",
        "select\n",
        "u1.user_id,\n",
        "\n",
        "\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then 1 else 0 end) ) as number_of_screen_views_7D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then 1 else 0 end) ) as number_of_screen_views_14D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then 1 else 0 end) ) as number_of_screen_views_30D,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then 1 else 0 end) ) as number_of_screen_views_60D\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'screen_view' and u1.user_id is not null\n",
        "   group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "sd as (\n",
        "select\n",
        "u1.user_id,\n",
        "\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_7Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_14Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_30Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_60Ds\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x , unnest(event_params) as ep\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'screen_view' and ep.key ='engagement_time_msec' and u1.user_id is not null\n",
        "   group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "sw2 as (\n",
        "select\n",
        "sw.*,\n",
        "sd.* except(user_id)\n",
        "from sw\n",
        "left join sd on sw.user_id = sd.user_id\n",
        ")\n",
        ",\n",
        "-- join tables\n",
        "\n",
        "\n",
        "p3 as (\n",
        "select\n",
        "p2.*,\n",
        "vd.* except(user_id),\n",
        "sw2.* except(user_id)\n",
        "from p2\n",
        "left join vd on p2.user_id = vd.user_id\n",
        "left join sw2 on p2.user_id = sw2.user_id\n",
        ")\n",
        ",\n",
        "\n",
        "--- purchases---\n",
        "\n",
        "pur as(\n",
        "\n",
        "\n",
        " select\n",
        " u1.user_id,\n",
        "\n",
        " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then itm.price_in_usd else 0 end),2) as total_revenue_7D,\n",
        " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then itm.price_in_usd else 0 end),2) as total_revenue_14D,\n",
        " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then itm.price_in_usd else 0 end),2) as total_revenue_30D,\n",
        " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then itm.price_in_usd else 0 end),2) as total_revenue_60D,\n",
        "\n",
        " date_diff({last_date_sql} , max(PARSE_DATE(\"%Y%m%d\", event_date)), DAY) as purchase_recency,\n",
        "\n",
        " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then 1 else 0 end) as purchase_events_60D,\n",
        " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then 1 else 0 end) as purchase_events_30D,\n",
        " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then 1 else 0 end) as purchase_events_14D,\n",
        " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then 1 else 0 end) as purchase_events_7D\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x , unnest(items) as itm\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id and u1.user_id is not null\n",
        "   where {time_frame} and event_name = 'purchase'\n",
        "   group by 1 )\n",
        ",\n",
        "\n",
        "\n",
        "-- join tables\n",
        "p4 as (\n",
        "select\n",
        "p3.*,\n",
        "pur.* except(user_id)\n",
        "from\n",
        "p3\n",
        "left join pur on p3.user_id = pur.user_id\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- total clicks --\n",
        "c1 as (\n",
        "select\n",
        "u1.user_id,\n",
        "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then 1 else 0 end) as total_clicks_7D,\n",
        "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then 1 else 0 end) as total_clicks_14D,\n",
        "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then 1 else 0 end) as total_clicks_30D\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'click' and u1.user_id is not null\n",
        "   group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- join tables\n",
        "p5 as (\n",
        "select\n",
        "p4.*,\n",
        "c1.* except(user_id)\n",
        "from\n",
        "p4\n",
        "left join c1 on p4.user_id = c1.user_id\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "-- predictive metrics\n",
        "pred as\n",
        "(\n",
        "SELECT\n",
        "u1.user_id,\n",
        "\n",
        "{pred_query}\n",
        "\n",
        "FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on x.user_pseudo_id = u1.user_pseudo_id where {time_frame} and u1.user_id is not null\n",
        "group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "-- join tables\n",
        "\n",
        "p6 as (\n",
        "select\n",
        "p5.*,\n",
        "pred.* except(user_id)\n",
        "from\n",
        "p5\n",
        "left join pred on p5.user_id = pred.user_id\n",
        ")\n",
        "\n",
        "-- NULL HANDLING --\n",
        "select\n",
        "user_id,\n",
        "continent,\n",
        "sub_continent,\n",
        "region,\n",
        "country,\n",
        "city,\n",
        "category,\n",
        "mobile_brand_name,\n",
        "operating_system,\n",
        "user_first_touch_timestamp,\n",
        "last_event_date,\n",
        "last_event_name,\n",
        "last_traffic_source_name,\n",
        "last_traffic_source_medium,\n",
        "last_traffic_source_source,\n",
        "IFNULL(user_ltv, 0) as user_ltv,\n",
        "IFNULL(number_of_page_views_7D, 0) as number_of_page_views_7D,\n",
        "IFNULL(number_of_page_views_14D, 0) as number_of_page_views_14D,\n",
        "IFNULL(number_of_page_views_30D, 0) as number_of_page_views_30D,\n",
        "IFNULL(number_of_page_views_60D, 0) as number_of_page_views_60D,\n",
        "IFNULL(visit_freq_7D, 0) as visit_freq_7D,\n",
        "IFNULL(visit_freq_14D, 0) as visit_freq_14D,\n",
        "IFNULL(visit_freq_30D, 0) as visit_freq_30D,\n",
        "IFNULL(visit_freq_60D, 0) as visit_freq_60D,\n",
        "IFNULL(visit_duration_7Ds, 0) as visit_duration_7Ds,\n",
        "IFNULL(visit_duration_14Ds, 0) as visit_duration_14Ds,\n",
        "IFNULL(visit_duration_30Ds, 0) as visit_duration_30Ds,\n",
        "IFNULL(visit_duration_60Ds, 0) as visit_duration_60Ds,\n",
        "IFNULL(number_of_screen_views_7D, 0) as number_of_screen_views_7D,\n",
        "IFNULL(number_of_screen_views_14D, 0) as number_of_screen_views_14D,\n",
        "IFNULL(number_of_screen_views_30D, 0) as number_of_screen_views_30D,\n",
        "IFNULL(number_of_screen_views_60D, 0) as number_of_screen_views_60D,\n",
        "IFNULL(screen_view_duration_7Ds, 0) as screen_view_duration_7Ds,\n",
        "IFNULL(screen_view_duration_14Ds, 0) as screen_view_duration_14Ds,\n",
        "IFNULL(screen_view_duration_30Ds, 0) as screen_view_duration_30Ds,\n",
        "IFNULL(screen_view_duration_60Ds, 0) as screen_view_duration_60Ds,\n",
        "IFNULL(total_revenue_7D, 0) as total_revenue_7D,\n",
        "IFNULL(total_revenue_14D, 0) as total_revenue_14D,\n",
        "IFNULL(total_revenue_30D, 0) as total_revenue_30D,\n",
        "IFNULL(total_revenue_60D, 0) as total_revenue_60D,\n",
        "IFNULL(purchase_recency, 0) as purchase_recency,\n",
        "IFNULL(purchase_events_60D, 0) as purchase_events_60D,\n",
        "IFNULL(purchase_events_30D, 0) as purchase_events_30D,\n",
        "IFNULL(purchase_events_14D, 0) as purchase_events_14D,\n",
        "IFNULL(purchase_events_7D, 0) as purchase_events_7D,\n",
        "IFNULL(total_clicks_7D, 0) as total_clicks_7D,\n",
        "IFNULL(total_clicks_14D, 0) as total_clicks_14D,\n",
        "IFNULL(total_clicks_30D, 0) as total_clicks_30D,\n",
        "{null_adjust_pred_aud}\n",
        "current_date() as crtdate\n",
        "from p6\n",
        ";\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ex4mxiseNwzd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if App_stream_to_ga4 == False:\n",
        "  remove_code_part1 = f\"\"\"sd as (\n",
        "select\n",
        "u1.user_id,\n",
        "\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 8 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_7Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 15 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_14Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 31 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_30Ds,\n",
        "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > {last_date_sql}- 61 then ep.value.int_value else 0 end) )/1000 as screen_view_duration_60Ds\n",
        "\n",
        "\n",
        "   FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x , unnest(event_params) as ep\n",
        "   left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
        "   where {time_frame} and event_name = 'screen_view' and ep.key ='engagement_time_msec' and u1.user_id is not null\n",
        "   group by 1\n",
        ")\n",
        ",\n",
        "\n",
        "\n",
        "sw2 as (\n",
        "select\n",
        "sw.*,\n",
        "sd.* except(user_id)\n",
        "from sw\n",
        "left join sd on sw.user_id = sd.user_id\n",
        ")\n",
        ",\"\"\"\n",
        "\n",
        "  remove_code_part2 = \"\"\",\n",
        "sw2.* except(user_id)\"\"\"\n",
        "\n",
        "  remove_code_part3 =\"\"\"left join sw2 on p2.user_id = sw2.user_id\"\"\"\n",
        "\n",
        "  remove_code_part4 =\"\"\"IFNULL(number_of_screen_views_7D, 0) as number_of_screen_views_7D,\n",
        "IFNULL(number_of_screen_views_14D, 0) as number_of_screen_views_14D,\n",
        "IFNULL(number_of_screen_views_30D, 0) as number_of_screen_views_30D,\n",
        "IFNULL(number_of_screen_views_60D, 0) as number_of_screen_views_60D,\n",
        "IFNULL(screen_view_duration_7Ds, 0) as screen_view_duration_7Ds,\n",
        "IFNULL(screen_view_duration_14Ds, 0) as screen_view_duration_14Ds,\n",
        "IFNULL(screen_view_duration_30Ds, 0) as screen_view_duration_30Ds,\n",
        "IFNULL(screen_view_duration_60Ds, 0) as screen_view_duration_60Ds,\"\"\"\n",
        "\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part1, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part2, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part3, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part4, \"\")\n"
      ],
      "metadata": {
        "id": "re1jUC7yd895"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Have_Ga4_custom_audiences == False:\n",
        "  remove_code_part5 = f\"\"\"-- predictive metrics\n",
        "pred as\n",
        "(\n",
        "SELECT\n",
        "u1.user_id,\n",
        "\n",
        "max(case when event_name = 'likely_sevenday_purchasers' then 1 else 0 end) as likely_sevenday_purchasers,\n",
        "max(case when event_name = 'first_time_sevenday_purchasers' then 1 else 0 end) as first_time_sevenday_purchasers,\n",
        "max(case when event_name = 'likely_sevenday_churning' then 1 else 0 end) as likely_sevenday_churning\n",
        "\n",
        "FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on x.user_pseudo_id = u1.user_pseudo_id where {time_frame} and u1.user_id is not null\n",
        "group by 1\n",
        ")\n",
        ",\"\"\"\n",
        "\n",
        "  remove_code_part6 = \"\"\",\n",
        "pred.* except(user_id)\"\"\"\n",
        "\n",
        "  remove_code_part7 =\"\"\"left join pred on p5.user_id = pred.user_id\"\"\"\n",
        "\n",
        "  remove_code_part8 =\"\"\"IFNULL(likely_sevenday_purchasers, 0) as likely_sevenday_purchasers,\n",
        "IFNULL(first_time_sevenday_purchasers, 0) as first_time_sevenday_purchasers,\n",
        "IFNULL(likely_sevenday_churning, 0) as likely_sevenday_churning,\"\"\"\n",
        "\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part5, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part6, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part7, \"\")\n",
        "  user_datamart_query = user_datamart_query.replace(remove_code_part8, \"\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qKnBcrIdTM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Have_Ga4_custom_audiences == False:\n",
        "  user_datamart_query=user_datamart_query.replace(pred_query,\"\")\n",
        "  user_datamart_query=user_datamart_query.replace(null_adjust_pred_aud,\"\")"
      ],
      "metadata": {
        "id": "69-pxzDqOH2a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(user_datamart_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKszk3MaeLTE",
        "outputId": "c45cf84b-d68e-46cf-e1a1-949d016ce246"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "create or replace table `arcelik-bi-project.goog123.user_id_data_ga4_20241101_20241103` as\n",
            "--- geo, device info, user_ltv —\n",
            "-- for each user assign the latest observed device\n",
            "with t1 as(\n",
            "select\n",
            "* except(RN)\n",
            "from\n",
            " (SELECT\n",
            " u1.user_id,\n",
            "\n",
            "\n",
            " geo.continent,\n",
            " geo.sub_continent,\n",
            " geo.region,\n",
            " geo.country,\n",
            " geo.city,\n",
            "\n",
            "\n",
            " device.category,\n",
            " device.mobile_brand_name,\n",
            " device.operating_system,\n",
            "\n",
            "\n",
            " user_first_touch_timestamp,\n",
            " user_ltv.revenue as user_ltv,\n",
            "\n",
            "\n",
            " row_number() over (partition by u1.user_id order by event_date desc) as RN\n",
            "\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and u1.user_id is not null\n",
            "   )\n",
            "where RN = 1\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- last events\n",
            "t2 as (\n",
            " select * except(RN)\n",
            " from\n",
            "   (SELECT\n",
            "   u1.user_id,\n",
            "   event_date as last_event_date,\n",
            "   event_name as last_event_name,\n",
            "   IFNULL(traffic_source.name, 'NOTSET') as last_traffic_source_name,\n",
            "   IFNULL(traffic_source.medium,'NOTSET') as last_traffic_source_medium,\n",
            "   IFNULL(traffic_source.`source`, 'NOTSET') as last_traffic_source_source,\n",
            "   row_number() over (partition by u1.user_id order by event_date desc) as RN\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and u1.user_id is not null    )\n",
            " where RN = 1\n",
            ")\n",
            ",\n",
            "-- join tables\n",
            "p1 as (\n",
            "select\n",
            "t1.*,\n",
            "t2.*  except(user_id)\n",
            "from t1\n",
            "left join t2 on t1.user_id = t2.user_id\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- total pageviews and the distinct days page viewed (visit frequency)\n",
            "\n",
            "\n",
            "pw as (\n",
            "select\n",
            "u1.user_id,\n",
            "\n",
            "\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then 1 else 0 end) ) as number_of_page_views_7D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then 1 else 0 end) ) as number_of_page_views_14D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then 1 else 0 end) ) as number_of_page_views_30D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then 1 else 0 end) ) as number_of_page_views_60D,\n",
            "\n",
            "\n",
            "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then event_date else null end) ) as visit_freq_7D,\n",
            "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then event_date else null end) ) as visit_freq_14D,\n",
            "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then event_date else null end) ) as visit_freq_30D,\n",
            "count(distinct (case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then event_date else null end) ) as visit_freq_60D\n",
            "\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and event_name = 'page_view' and u1.user_id is not null\n",
            "   group by 1\n",
            "\n",
            "),\n",
            "\n",
            "\n",
            "p2 as(\n",
            "select\n",
            "p1.*,\n",
            "pw.* except(user_id)\n",
            "from p1\n",
            "left join pw on p1.user_id=pw.user_id\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- visit durations\n",
            "vd as (\n",
            "select\n",
            "u1.user_id,\n",
            "\n",
            "\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then ep.value.int_value else 0 end) )/1000 as visit_duration_7Ds,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then ep.value.int_value else 0 end) )/1000 as visit_duration_14Ds,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then ep.value.int_value else 0 end) )/1000 as visit_duration_30Ds,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then ep.value.int_value else 0 end) )/1000 as visit_duration_60Ds\n",
            "\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x, unnest(event_params) as ep\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and event_name = 'page_view' and ep.key ='engagement_time_msec' and u1.user_id is not null\n",
            "   group by 1\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- screen view and screen view durations (use if app is also linked with GA4)\n",
            "sw as (\n",
            "select\n",
            "u1.user_id,\n",
            "\n",
            "\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then 1 else 0 end) ) as number_of_screen_views_7D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then 1 else 0 end) ) as number_of_screen_views_14D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then 1 else 0 end) ) as number_of_screen_views_30D,\n",
            "sum ((case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then 1 else 0 end) ) as number_of_screen_views_60D\n",
            "\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and event_name = 'screen_view' and u1.user_id is not null\n",
            "   group by 1\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "\n",
            "-- join tables\n",
            "\n",
            "\n",
            "p3 as (\n",
            "select\n",
            "p2.*,\n",
            "vd.* except(user_id)\n",
            "from p2\n",
            "left join vd on p2.user_id = vd.user_id\n",
            "\n",
            ")\n",
            ",\n",
            "\n",
            "--- purchases---\n",
            "\n",
            "pur as(\n",
            "\n",
            "\n",
            " select\n",
            " u1.user_id,\n",
            "\n",
            " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then itm.price_in_usd else 0 end),2) as total_revenue_7D,\n",
            " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then itm.price_in_usd else 0 end),2) as total_revenue_14D,\n",
            " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then itm.price_in_usd else 0 end),2) as total_revenue_30D,\n",
            " round(sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then itm.price_in_usd else 0 end),2) as total_revenue_60D,\n",
            "\n",
            " date_diff(CAST('2024-11-03' AS DATE) , max(PARSE_DATE(\"%Y%m%d\", event_date)), DAY) as purchase_recency,\n",
            "\n",
            " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 61 then 1 else 0 end) as purchase_events_60D,\n",
            " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then 1 else 0 end) as purchase_events_30D,\n",
            " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then 1 else 0 end) as purchase_events_14D,\n",
            " sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then 1 else 0 end) as purchase_events_7D\n",
            "\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x , unnest(items) as itm\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id and u1.user_id is not null\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and event_name = 'purchase'\n",
            "   group by 1 )\n",
            ",\n",
            "\n",
            "\n",
            "-- join tables\n",
            "p4 as (\n",
            "select\n",
            "p3.*,\n",
            "pur.* except(user_id)\n",
            "from\n",
            "p3\n",
            "left join pur on p3.user_id = pur.user_id\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- total clicks --\n",
            "c1 as (\n",
            "select\n",
            "u1.user_id,\n",
            "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 8 then 1 else 0 end) as total_clicks_7D,\n",
            "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 15 then 1 else 0 end) as total_clicks_14D,\n",
            "sum(case when PARSE_DATE(\"%Y%m%d\", event_date) > CAST('2024-11-03' AS DATE)- 31 then 1 else 0 end) as total_clicks_30D\n",
            "\n",
            "   FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "   left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on u1.user_pseudo_id = x.user_pseudo_id\n",
            "   where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and event_name = 'click' and u1.user_id is not null\n",
            "   group by 1\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- join tables\n",
            "p5 as (\n",
            "select\n",
            "p4.*,\n",
            "c1.* except(user_id)\n",
            "from\n",
            "p4\n",
            "left join c1 on p4.user_id = c1.user_id\n",
            ")\n",
            ",\n",
            "\n",
            "\n",
            "-- predictive metrics\n",
            "pred as\n",
            "(\n",
            "SELECT\n",
            "u1.user_id,\n",
            "\n",
            "\n",
            "\n",
            "FROM `arcelik-bi-project.analytics_294368252.events_*` as x\n",
            "left join `arcelik-bi-project.goog123.user_mapping_table` as u1 on x.user_pseudo_id = u1.user_pseudo_id where (_TABLE_SUFFIX BETWEEN '20241101' AND '20241103') and u1.user_id is not null\n",
            "group by 1\n",
            ")\n",
            ",\n",
            "\n",
            "-- join tables\n",
            "\n",
            "p6 as (\n",
            "select\n",
            "p5.*\n",
            "from\n",
            "p5\n",
            "\n",
            ")\n",
            "\n",
            "-- NULL HANDLING --\n",
            "select\n",
            "user_id,\n",
            "continent,\n",
            "sub_continent,\n",
            "region,\n",
            "country,\n",
            "city,\n",
            "category,\n",
            "mobile_brand_name,\n",
            "operating_system,\n",
            "user_first_touch_timestamp,\n",
            "last_event_date,\n",
            "last_event_name,\n",
            "last_traffic_source_name,\n",
            "last_traffic_source_medium,\n",
            "last_traffic_source_source,\n",
            "IFNULL(user_ltv, 0) as user_ltv,\n",
            "IFNULL(number_of_page_views_7D, 0) as number_of_page_views_7D,\n",
            "IFNULL(number_of_page_views_14D, 0) as number_of_page_views_14D,\n",
            "IFNULL(number_of_page_views_30D, 0) as number_of_page_views_30D,\n",
            "IFNULL(number_of_page_views_60D, 0) as number_of_page_views_60D,\n",
            "IFNULL(visit_freq_7D, 0) as visit_freq_7D,\n",
            "IFNULL(visit_freq_14D, 0) as visit_freq_14D,\n",
            "IFNULL(visit_freq_30D, 0) as visit_freq_30D,\n",
            "IFNULL(visit_freq_60D, 0) as visit_freq_60D,\n",
            "IFNULL(visit_duration_7Ds, 0) as visit_duration_7Ds,\n",
            "IFNULL(visit_duration_14Ds, 0) as visit_duration_14Ds,\n",
            "IFNULL(visit_duration_30Ds, 0) as visit_duration_30Ds,\n",
            "IFNULL(visit_duration_60Ds, 0) as visit_duration_60Ds,\n",
            "\n",
            "IFNULL(total_revenue_7D, 0) as total_revenue_7D,\n",
            "IFNULL(total_revenue_14D, 0) as total_revenue_14D,\n",
            "IFNULL(total_revenue_30D, 0) as total_revenue_30D,\n",
            "IFNULL(total_revenue_60D, 0) as total_revenue_60D,\n",
            "IFNULL(purchase_recency, 0) as purchase_recency,\n",
            "IFNULL(purchase_events_60D, 0) as purchase_events_60D,\n",
            "IFNULL(purchase_events_30D, 0) as purchase_events_30D,\n",
            "IFNULL(purchase_events_14D, 0) as purchase_events_14D,\n",
            "IFNULL(purchase_events_7D, 0) as purchase_events_7D,\n",
            "IFNULL(total_clicks_7D, 0) as total_clicks_7D,\n",
            "IFNULL(total_clicks_14D, 0) as total_clicks_14D,\n",
            "IFNULL(total_clicks_30D, 0) as total_clicks_30D,\n",
            "\n",
            "current_date() as crtdate\n",
            "from p6\n",
            ";\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file name\n",
        "file_name = \"user_datamart_query.sql\"  # You can use .sql extension to indicate that it is an SQL file\n",
        "\n",
        "# Write the SQL query to the file\n",
        "with open(file_name, \"w\") as file:\n",
        "    file.write(user_datamart_query)"
      ],
      "metadata": {
        "id": "t5-Zd3rAdvo3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tables in Bigquery"
      ],
      "metadata": {
        "id": "IFvw2g5pfOXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queryjob1 =client.query(user_id_mapping_query)\n",
        "queryjob1.result()\n",
        "queryjob2 = client.query(user_datamart_query)\n",
        "queryjob2.result()"
      ],
      "metadata": {
        "id": "GPP3QRb2fYVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc55282-bdc9-48e9-f7ac-c99d7f4d28ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x78402d23d810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Join with CRM Data\n",
        "\n",
        "*Make sure you have a hashed email column ready in your CRM table for activation*"
      ],
      "metadata": {
        "id": "EoTY3gWAtT4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CRM-GA4 Inputs\n",
        "Use_previously_built_datamart_in_first_stage = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Use_previously_built_datamart_in_first_stage:\n",
        "  GA4_datamart_table_name = f\"{Big_query_project_name}.{Data_set_name}.user_id_data_ga4_{table_suffix_start_date}_{table_suffix_end_date}\"\n",
        "\n",
        "else:\n",
        "  GA4_datamart_table_name = input(\"Enter GA4 Datamart Table Name (format=project_name.dataset_name.table_name): \") or f\"{Big_query_project_name}.{Data_set_name}.user_id_data_ga4_{table_suffix_start_date}_{table_suffix_end_date}\"\n",
        "\n",
        "#GA4_datamart_table_name = GA4_datamart_full_name #@param {type:\"string\"}\n",
        "CRM_table_full_name = \"Your_project_name.your_dataset_name.crm_table_name\" #@param {type:\"string\"}\n",
        "CRM_user_id_alias = \"user_id_column_name\" #@param {type:\"string\"}\n",
        "Output_table_name = \"ota_ga4_joined\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "IQoxNRjyTTKA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Use_previously_built_datamart_in_first_stage:**\n",
        "The table generated during the build datamart stage is the default table for joining with CRM data. If you wish to join with a different table, such as the scored output table from a prediction model, deselect the checkbox and utilize the specified input section. Input format exp: project_name.dataset_name.table_name\n",
        "\n",
        "* **CRM_table_full_name:** Make sure you write the name in the following format: your_projectname.dataset_name.crm_table_name. Your CRM table's dataset should be in the same region with the GA4 dataset for the join.\n",
        "\n",
        "* **CRM_user_id_alias:** the name of the user id field. This user id will be used as match key to join with GA4 data.\n",
        "\n",
        "* **Output_table_name:** Rename output final table that includes CRM and GA4 data"
      ],
      "metadata": {
        "id": "cuymrjWCUBYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the CRM - GA4 join query"
      ],
      "metadata": {
        "id": "SGIsxJlhftp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crm_ga4_join_query = f\"\"\"\n",
        "create or replace table `{Big_query_project_name}.{Data_set_name}.{Output_table_name}` as\n",
        "SELECT\n",
        "*\n",
        "FROM `{CRM_table_full_name}` t1\n",
        "left join `{GA4_datamart_table_name}` t2 on cast(t1.{CRM_user_id_alias} as string)= cast(t2.user_id as string)\n",
        ";\"\"\"\n",
        "\n",
        "# Specify the file name\n",
        "query_name = \"crm_ga4_join_query.sql\"  # You can use .sql extension to indicate that it is an SQL file\n",
        "\n",
        "# Write the SQL query to the file\n",
        "with open(query_name, \"w\") as file:\n",
        "    file.write(crm_ga4_join_query)"
      ],
      "metadata": {
        "id": "f9A_5nqbfzWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tables in Bigquery"
      ],
      "metadata": {
        "id": "hfw3I5foiQU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queryjob3 = client.query(crm_ga4_join_query)\n",
        "queryjob3.result()"
      ],
      "metadata": {
        "id": "ViQSPO2OiURC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae18a3a-3751-4610-c56f-7119c22b1ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7c07366266e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment with Modeling"
      ],
      "metadata": {
        "id": "GyKWKI7RMiRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Event Propensity\n",
        "\n",
        "![Example Image](https://drive.google.com/uc?export=view&id=1cc4mVGgCyayjX4m4FCETUlFHSYlvhRIL)\n",
        "\n",
        "\n",
        "\n",
        "BigQuery ML has additional requirements: training AutoML models are supported in certain locations only.\n",
        "Check your dateset location before starting to experiment!\n",
        "\n",
        "\n",
        "[BqML and locations mapping](https://cloud.google.com/bigquery/docs/locations#bqml-loc)\n",
        "\n",
        "More info about the model used. [link](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree#dropout)\n",
        "\n",
        "\n",
        "\n",
        "If you get unsupported dataset location error [link](https://cloud.google.com/knowledge/kb/bigquery-unsupported-dataset-location-for-automl-jobs-000004465)\n",
        "\n",
        "\n",
        "*Experiment predicts over created user datamart query by default*\n",
        "\n"
      ],
      "metadata": {
        "id": "SEFUwr8vvP6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Event propensity model inputs\n",
        "Target_time_window_start_date= \"2024-01-01\" #@param {type:\"date\"}\n",
        "Target_time_window_end_date= \"2024-02-01\" #@param {type:\"date\"}\n",
        "Learning_window_start_date= \"2023-10-01\" #@param {type:\"date\"}\n",
        "Target_event= \"view_item\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "VA-QsqtSNByq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the modeling queries"
      ],
      "metadata": {
        "id": "z6AtGqXNMNF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adjust learning and target time frames\n",
        "\n",
        "target_start_table_suffix = reformat_date(Target_time_window_start_date)\n",
        "target_end_table_suffix = reformat_date(Target_time_window_end_date)\n",
        "target_time_frame = f\"(_TABLE_SUFFIX BETWEEN '{target_start_table_suffix}' AND '{target_end_table_suffix}')\"\n",
        "\n",
        "flagging_query= f\"\"\"\n",
        "create or replace table `{Big_query_project_name}.{Data_set_name}.user_flags_{target_start_table_suffix}_{target_end_table_suffix}` as\n",
        "SELECT\n",
        "u1.user_id,\n",
        "max(case when event_name = '{Target_event}' then 1 else 0 end) as target_{Target_event},\n",
        "FROM `{Big_query_project_name}.{GA4_table_name}.events_*` as x\n",
        "left join `{Big_query_project_name}.{Data_set_name}.user_mapping_table` as u1 on x.user_pseudo_id = u1.user_pseudo_id where {target_time_frame} and u1.user_id is not null\n",
        "group by 1;\"\"\"\n",
        "\n",
        "Target_start_datetime_object = pd.to_datetime(Target_time_window_start_date)\n",
        "\n",
        "#define training window\n",
        "# Subtract 1 day from the target start date. Create the end date of learning period. learning period should end one day prior to target period.\n",
        "Target_start_datetime_object_minus_one_day = Target_start_datetime_object - pd.DateOffset(days=1)\n",
        "Target_start_datetime_object_minus_one_day = Target_start_datetime_object_minus_one_day.date()\n",
        "\n",
        "\n",
        "features_start_date_table_suffix = reformat_date(Learning_window_start_date)\n",
        "features_end_date_table_suffix = reformat_date(str(Target_start_datetime_object_minus_one_day))\n",
        "\n",
        "learning_time_frame = f\"(_TABLE_SUFFIX BETWEEN '{features_start_date_table_suffix}' AND '{features_end_date_table_suffix}')\"\n",
        "\n",
        "#adjust the time frame for the training set and build training table\n",
        "training_period_query = user_datamart_query.replace(time_frame, learning_time_frame)\n",
        "training_period_query = training_period_query.replace(f\"user_id_data_ga4_{table_suffix_start_date}_{table_suffix_end_date}\", f\"user_features_train_temp_{features_start_date_table_suffix}_{features_end_date_table_suffix}\")\n",
        "\n",
        "\n",
        "#outlier handling using winsorizing\n",
        "winsor_columns = [\n",
        "                  \"number_of_page_views_7D\",\n",
        "                  \"number_of_page_views_14D\",\n",
        "                  \"number_of_page_views_30D\",\n",
        "                  \"visit_freq_7D\",\n",
        "                  \"visit_freq_14D\",\n",
        "                  \"visit_freq_30D\",\n",
        "                  \"visit_freq_60D\",\n",
        "                  \"visit_duration_7Ds\",\n",
        "                  \"visit_duration_14Ds\",\n",
        "                  \"visit_duration_30Ds\",\n",
        "                  \"visit_duration_60Ds\",\n",
        "                  \"total_revenue_7D\",\n",
        "                  \"total_revenue_14D\",\n",
        "                  \"total_revenue_30D\",\n",
        "                  \"total_revenue_60D\",\n",
        "                  \"purchase_recency\",\n",
        "                  \"purchase_events_30D\",\n",
        "                  \"purchase_events_14D\",\n",
        "                  \"purchase_events_7D\",\n",
        "                  \"total_clicks_7D\",\n",
        "                  \"total_clicks_14D\",\n",
        "                  \"total_clicks_30D\"]\n",
        "\n",
        "winsor_query_0 = \"\"\n",
        "\n",
        "for column_name in winsor_columns:\n",
        "  winsor_template = f\"\"\"IF({column_name}> (PERCENTILE_CONT({column_name}, 0.97) OVER ()), round(PERCENTILE_CONT({column_name}, 0.97) OVER (),2), {column_name}) as {column_name},\"\"\"\n",
        "  winsor_query_0 += winsor_template + '\\n'\n",
        "\n",
        "# Remove the trailing comma from the last line\n",
        "winsor_query_0 = winsor_query_0.rstrip(',\\n')\n",
        "\n",
        "#complete winsorizin query\n",
        "winsor_query = sql_query = f\"\"\"create or replace table `{Big_query_project_name}.{Data_set_name}.user_features_train_{features_start_date_table_suffix}_{features_end_date_table_suffix}` as\n",
        "SELECT\n",
        "    * EXCEPT({', '.join(winsor_columns)}),\n",
        "    {winsor_query_0}\n",
        "FROM\n",
        "    `{Big_query_project_name}.{Data_set_name}.user_features_train_temp_{features_start_date_table_suffix}_{features_end_date_table_suffix}`;\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#undersampling query and joining flagged users with training features\n",
        "undersampling_query = f\"\"\"create or replace table `{Big_query_project_name}.{Data_set_name}.train_set_{Target_event}` as\n",
        "with train1 as\n",
        "(SELECT\n",
        "t1.user_id,\n",
        "target_{Target_event},\n",
        "t2.* except(user_id)\n",
        " FROM `{Big_query_project_name}.{Data_set_name}.user_flags_{target_start_table_suffix}_{target_end_table_suffix}` t1\n",
        " inner join `{Big_query_project_name}.{Data_set_name}.user_features_train_{features_start_date_table_suffix}_{features_end_date_table_suffix}` t2 on t1.user_id = t2.user_id\n",
        ")\n",
        ",\n",
        "PositiveSamples AS (\n",
        "  SELECT *\n",
        "  FROM train1\n",
        "  WHERE target_{Target_event} = 1\n",
        ")\n",
        ", NegativeSamples AS (\n",
        "  SELECT *,\n",
        "         ROW_NUMBER() OVER (ORDER BY RAND()) as row_num\n",
        "  FROM train1\n",
        "  WHERE target_{Target_event} = 0\n",
        ")\n",
        "\n",
        "SELECT *\n",
        "FROM PositiveSamples\n",
        "UNION ALL\n",
        "SELECT *except(row_num)\n",
        "FROM NegativeSamples\n",
        "WHERE row_num <= (SELECT COUNT(*) FROM PositiveSamples);\"\"\"\n",
        "\n",
        "\n",
        "# training the model boosted tree classifier\n",
        "model_query = f\"\"\"\n",
        "create or replace model `{Big_query_project_name}.{Data_set_name}.my_model`\n",
        "options(\n",
        "  MODEL_TYPE = 'BOOSTED_TREE_CLASSIFIER',\n",
        "  CATEGORY_ENCODING_METHOD = 'LABEL_ENCODING',\n",
        "  ENABLE_GLOBAL_EXPLAIN = TRUE,\n",
        "  DATA_SPLIT_METHOD = 'AUTO_SPLIT',\n",
        "  INPUT_LABEL_COLS = ['target_{Target_event}']\n",
        ")\n",
        "\n",
        "as\n",
        "\n",
        "SELECT *except(user_id,crtdate, last_event_date) FROM `{Big_query_project_name}.{Data_set_name}.train_set_{Target_event}`;\n",
        "\"\"\"\n",
        "\n",
        "clean_up_query = f\"\"\"drop table `{Big_query_project_name}.{Data_set_name}.user_features_train_temp_{features_start_date_table_suffix}_{features_end_date_table_suffix}`;\n",
        "drop table `{Big_query_project_name}.{Data_set_name}.user_features_train_{features_start_date_table_suffix}_{features_end_date_table_suffix}`;\n",
        "drop table `{Big_query_project_name}.{Data_set_name}.user_flags_{target_start_table_suffix}_{target_end_table_suffix}`;\"\"\"\n",
        "\n",
        "training_query = flagging_query + '\\n' + training_period_query + '\\n' + winsor_query + '\\n' + undersampling_query + '\\n' + model_query + '\\n' + clean_up_query\n",
        "\n",
        "training_query_name = \"model_training_query.sql\"\n",
        "\n",
        "# Write the SQL query to the file\n",
        "with open(training_query_name, \"w\") as file:\n",
        "    file.write(training_query)\n",
        "\n",
        "\n",
        "\n",
        "prediction_query= f\"\"\"create or replace table `{Big_query_project_name}.{Data_set_name}.predictions_by_customer_target_{Target_event}` as\n",
        "SELECT\n",
        "  user_id,\n",
        "  predicted_target_{Target_event},\n",
        "  predicted_target_{Target_event}_probs\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `{Big_query_project_name}.{Data_set_name}.my_model`,\n",
        "    (\n",
        "    SELECT\n",
        "  *\n",
        "    FROM\n",
        "      `{Big_query_project_name}.{Data_set_name}.user_id_data_ga4_{table_suffix_start_date}_{table_suffix_end_date}`));\"\"\"\n",
        "\n",
        "\n",
        "prediction_query_name = \"model_prediction_query.sql\"  # You can use .sql extension to indicate that it is an SQL file\n",
        "\n",
        "# Write the SQL query to the file\n",
        "with open(prediction_query_name, \"w\") as file:\n",
        "    file.write(prediction_query)"
      ],
      "metadata": {
        "id": "4y7oR--vN3-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tables in Bigquery"
      ],
      "metadata": {
        "id": "3leRQR4IbRgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queryjob4= client.query(training_query)\n",
        "queryjob4.result()\n",
        "\n",
        "queryjob5 = client.query(prediction_query)\n",
        "queryjob5.result()"
      ],
      "metadata": {
        "id": "Gcd6ffGgR7lZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ca5d57-f6ca-481d-ffc8-0d225ffdec86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7c0736627220>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}